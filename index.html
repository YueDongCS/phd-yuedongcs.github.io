<!DOCTYPE HTML>
<!--
   Read Only by HTML5 UP
   html5up.net | @ajlkn
   Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
   -->
<html>
   <head>
      <title>Yue Dong</title>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
      <link rel="stylesheet" href="assets/css/main.css" />

      
      <!-- Global site tag (gtag.js) - Google Analytics -->
         <script async src="https://www.googletagmanager.com/gtag/js?id=G-5RZSERDD5F"></script>
         <script>
           window.dataLayer = window.dataLayer || [];
           function gtag(){dataLayer.push(arguments);}
           gtag('js', new Date());

           gtag('config', 'G-5RZSERDD5F');
         </script>
   </head>
   <body class="is-preload">
      <!-- Header -->
      <section id="header">
         <header>
            <span class="image avatar"><img src="images/yue_profile.jpg" alt="" /></span>
            <h1 id="logo"><a href="#">Yue Dong 董悦</a></h1>
            <!-- <p> Assistant Professor (Jan. 2023) <br />
               University of California, Riverside  <br />
                    </p> -->
         </header>
         <nav id="nav">
            <ul>
               <li><a href="#one" class="active">Introduction</a></li>
               <li><a href="#two">News</a></li>
               <li><a href="#three">Research</a></li>
               <li><a href="#four">Publications</a></li>
               <li><a href="#five">Services</a></li>
               <li><a href="#six">Teachings</a></li>
               <li><a href="#seven">Awards</a></li>
               <li><a href="#Eight">Talks</a></li>
            </ul>
         </nav>
         <footer>
            <ul class="icons">
               <li><a href="images/CV.pdf" class="fas fa-address-card"><span class="label"></span></a></li>
               <li><a href="https://twitter.com/yuedongcs" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
               <li><a href="https://scholar.google.ca/citations?user=WYkn4loAAAAJ&hl=en" class="fa fa-graduation-cap"><span class="label"></span></a></li>
               <!-- <li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li> -->
               <li><a href="https://www.linkedin.com/in/yuedongcs/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li> 
               <li><a href="https://github.com/yuedongcs" class="icon brands fa-github"><span class="label">Github</span></a></li>
               <li><a href="mailto:yuedongcs@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
            </ul>
         </footer>
      </section>
      <!-- Wrapper -->
      <div id="wrapper">
      <!-- Main -->
      <div id="main">
         <!-- One -->
         <section id="one">
            <div class="image main" data-position="center">
               <img src="images/wooden-bridge-banff.jpg" alt="" />
            </div>
            <div class="container">
               <p>Hi, I am Yue Dong, a final-year PhD student in Computer Science at McGill University/ <a href="https://mila.quebec/en/">MILA</a>, supervised by Dr. <a href="https://www.cs.mcgill.ca/~jcheung/index.html">Jackie Cheung</a>. I received my bachelor's and master's degrees in Mathematics from the University of Ottawa, co-supervised by Dr. <a href="https://sites.google.com/site/vpestov2010/home/">Vladimir Pestov</a>  and Dr. <a href="https://www.site.uottawa.ca/~nat/">Nathalie Japkowicz</a>. Before that, I studied Clinical Medicine at Xi'an Jiaotong University (西安交通大学).</p>
               <p>I am broadly interested in natural language processing, deep learning, and artificial intelligence. My current primary research interests are text summarization and conditional text generation. I interned at Google AI, AI2, Microsoft, and Huawei Noah’s Ark Lab during my PhD. </p>
               <p><strong><font color='orange'>I will join <a href="https://www1.cs.ucr.edu/">the CSE Department</a> at the <a href="https://www.ucr.edu/">University of California, Riverside</a> as an assistant professor in January 2023. I am looking for self-motivated PhDs / masters / interns to work in the area of Trustworthy and Efficient NLP, please consider <a href="https://www1.cs.ucr.edu/graduate/admissions/overview">applying</a>  if you are interested in working with me. </font></strong></p>
               <!--
                  One of my first-authored papers has won the best paper award at the 29th Canadian AI conference. I interned with Pat Verga and William Cohen at Google AI in Pittsburgh in summer 2021. 
                  Previously, I interned at AI2 with Chandra Bhagavatula and Yejin Choi; Microsoft with Shuohang Wang, Zhe Gan, Yu Cheng, and Jingjing Liu; Huawei Noah’s Ark Lab with Mehdi Rezagholizadeh. I am grateful to have been supported by NSERC CGS D scholarship.
                      --> 	
               <p style="text-align:center">
                  <a href="mailto:yuedongcs@gmail.com">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.ca/citations?user=WYkn4loAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                  <!-- <a href="https://github.com/yuedongcs">Github</a> &nbsp/&nbsp -->
                  <a href="https://twitter.com/yuedongcs">Twitter</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/yuedongcs/">LinkedIn</a> &nbsp/&nbsp
                  <a href="images/CV.pdf">CV</a> &nbsp/&nbsp                
                  <a href="images/Yue_Dong_Research_Statement.pdf">Research Statement</a> &nbsp/&nbsp    
                  <a href="https://www.1point3acres.com/bbs/thread-890304-1-1.html">招生</a>
               </p>
            </div>
         </section>
         <!-- Two -->
         <section id="two">
            <div class="container">
               <h3>News</h3>
               <div style="overflow-y: scroll; height:100px;">
                  <ul>
                     <li>
                        <strong>[10/2022]</strong> Our paper "Faithful to the Document or to the World? Mitigating Hallucinations via Entity-Linked Knowledge in Abstractive Summarization" has been accepted to EMNLP 2022.
                     </li>
                     <li>
                        <strong>[10/2022]</strong> Our paper "Learning with Rejection for Abstractive Text Summarization" has been accepted to EMNLP 2022.
                     </li>
                     <li>
                        <strong>[07/2022]</strong> Our workshop on "Efficient Natural Language and Speech Processing (ENLSP-II): The Future of Pre-trained Models" has been accepted to NeurIPS 2022.
                     </li>
                     <li>
                        <strong>[04/2022]</strong> I will be joining the University of Califonia, Riverside as a tenure-track assistant professor.
                     </li>
                     <li>
                        <strong>[12/2021]</strong> Our "Text Generation with Text-Editing Models" tutorial has been accepted to NAACL 2022.
                     </li>
                  </ul>
               </div>
            </div>
         </section>
         <!-- Three -->
         <section id="three">
            <div class="container">
               <h3>Research</h3>
               My primary research interests are in the fields of Natural Language Processing, Machine Learning, Artificial Intelligence, with broader interests in Statistical Learning, Computer Vision, and AI-Powered Social Intelligence.
               <ul>
                  <li><strong>Conditional Text Generation:</strong> Learning to assign probabilities to text sequences given some (long-term) conditioning context, addressing tasks such as text summarization, conversational AI, and machine translation.</li>
                  <li><strong>Controllable Text Generation:</strong> Text generation with control over output attributes, such as topic, style, and sentiment. </li>
                  <li><strong>Multimodal Learning:</strong> Combining different modalities of information for performance improvement, e.g. learning semantic correspondences between language and vision.</li>
                  <li><strong>Trustworthy NLP:</strong> Developing robust, fair, factual, knowledge-grouned, explainable and privacy-preserving language models.</li>
                  <li><strong>AI for Social Good:</strong> Fake news detection; biases reduction & fairness;  empathic text generation.</li>
               </ul>
            </div>
         </section>
         <!-- Four -->
         <section id="four">
            <div class="container">
               <h3>Publications</h3>
               <br>
               <ul>
                   <h4><u>2022</u></h4>
                  <li>
                     <strong> <a href="">Faithful to the Document or to the World? Mitigating Hallucinations via Entity-Linked Knowledge in Abstractive Summarization

</a>  </strong><br>
                     <strong> Yue Dong </strong> John Wieting and Pat Verga <br>
                     <em> <strong>Findings of EMNLP</strong>, 2022 </em>  
                  </li>
                  <li>
                     <strong> <a href="">Learning with Rejection for Abstractive Text Summarization</a>  </strong><br>
                     Meng Cao, <strong> Yue Dong </strong>, Jingyi He and Jackie Chi Kit Cheung <br>
                     <em> <strong>EMNLP</strong>, 2022 </em>  
                  </li>
                  <li>
                     <strong> <a href="https://arxiv.org/pdf/2109.09784.pdf">Inspecting the Factuality of Hallucinated Entities in Abstractive Summarization</a>  </strong><br>
                     Meng Cao, <strong> Yue Dong </strong> and Jackie C. K. Cheung <br>
                     <em> <strong>ACL</strong>, 2022 </em>  
                  </li>
                  <br>
                  <h4><u>2021</u></h4>
                  <li>
                     <strong> <a href="https://arxiv.org/pdf/2101.00371.pdf">On-the-Fly Attention Modulation for Neural Generation </a> </strong><br>
                     <strong>Yue Dong</strong>, Chandra Bhagavatula, Ximing Lu, Jena D. Hwang, Antoine Bosselut, Jackie Chi Kit Cheung and Yejin Choi <br>
                     <em> <strong>ACL Findings</strong>, 2022 </em> 
                  </li>
                  <li>
                     <strong> <a href="https://aclanthology.org/2021.acl-short.137.pdf">Bringing Structure into Summaries: a Faceted Summarization Dataset for Long Scientific Documents</a>  </strong><br>
                     Rui Meng, khushboo Thaker, Lei Zhang, <strong>Yue Dong</strong>, Xingdi Yuan, Tong Wang and Daqing He <br>
                     <em> <strong>ACL</strong>, 2021 </em> [<a href="https://github.com/hfthair/emerald_crawler">code</a>] 
                  </li>
                  <li>
                     <strong> <a href="https://arxiv.org/pdf/2005.00513.pdf">Discourse-Aware Unsupervised Summarization for Long Scientific Documents</a> </strong><br>
                     <strong>Yue Dong*</strong>, Andrei Romascanu* and Jackie C. K. Cheung <br>
                     <em> <strong>EACL</strong>, 2021 </em> [<a href="https://github.com/mirandrom/HipoRank">code</a>] 
                  </li>
                  <br>
                  <h4><u>2020</u></h4>
                  <li>
                     <strong> <a href="https://aclanthology.org/2020.emnlp-main.749/">Multi-Fact Correction in Abstractive Text Summarization</a>   </strong><br>
                     <strong> Yue Dong </strong>, Shuohang Wang, Zhe Gan, Yu Cheng, Jackie C. K. Cheung and Jingjing Liu <br>
                     <em> <strong>ENMLP</strong>, 2020 </em>  
                  </li>
                  <li>
                     <strong> <a href="https://aclanthology.org/2020.emnlp-main.648/"> Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles </a> </strong><br>
                     Yao Lu, <strong>Yue Dong</strong>, and Laurent Charlin <br>
                     <em> <strong>EMNLP</strong>, 2020 </em> [<a href="https://github.com/yaolu/Multi-XScience">code</a>] 
                  </li>
                  <li>
                     <strong> <a href="https://aclanthology.org/2020.emnlp-main.506/"> Factual Error Correction for Abstractive Summarization Models</a>   </strong><br>
                     Meng Cao, <strong>Yue Dong</strong>, Jiapeng Wu and Jackie C. K. Cheung <br>
                     <em> <strong>EMNLP</strong>, 2020 </em> [<a href="https://github.com/mcao516/Factual-Error-Correction">code</a>] 
                  </li>
                  <br>
                  <h4><u>2019</u></h4>
                  <li>
                     <strong> <a href="https://aclanthology.org/P19-1331/">EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing</a>  </strong><br>
                     <strong>Yue Dong</strong>, Zichao Li, Mehdi Rezagholizadeh and Jackie Cheung <br>
                     <em> <strong>ACL</strong>, 2019 </em> [<a href="https://github.com/yuedongP/EditNTS">code</a>] [<a href=" https://vimeo.com/384771870">talk</a>] 
                  </li>
                  <li>
                     <strong> <a href="https://aclanthology.org/D19-1620/">Countering the Effects of Lead Bias in News Summarization via Multi-Stage Training and Auxiliary Losses</a>  </strong><br>
                     <strong>Yue Dong*</strong>, Matt Grenander*, Jackie Cheung and Annie Louis <br>
                     <em> <strong>EMNLP-IJCNLP</strong>, 2019 </em> [<a href="https://github.com/mgrenander/banditsum-kl">code</a>] 
                  </li>
                  <li>
                     <strong> <a href="https://aclanthology.org/P19-1331/">Learning Multi-task Communication with Message Passing for Sequence Learning</a>  </strong><br>
                     Pengfei Liu, <strong>Yue Dong</strong>, Jie Fu, Xipeng Qiu and Jackie Cheung <br>
                     <em> <strong>AAAI</strong>, 2019 </em> 
                  </li>
                  <br>
                  <h4><u>2018</u></h4>
                  <li>
                     <strong> <a href="https://aclanthology.org/D18-1409/">BanditSum: Extractive Summarization as a Contextual Bandit </a>  </strong><br>
                     <strong>Yue Dong</strong>, Yikang Shen, Eric Crawford, Herke van Hoof and Jackie Chi Kit Cheung <br>
                     <em> <strong>EMNLP</strong>, 2018 </em> [<a href="https://github.com/yuedongP/BanditSum">code</a>][<a href=" https://vimeo.com/306160623">talk</a>] 
                  </li>
                  <li>
                     <strong> <a href="https://aclanthology.org/D18-1094/">A Hierarchical Neural Attention-based Text Classifier</a>   </strong><br>
                     Koustuv Sinha, <strong>Yue Dong</strong>, Jackie Chi Kit Cheung and Derek Ruths <br>
                     <em> <strong>EMNLP</strong> 2018 </em> [<a href="https://github.com/koustuvsinha/hier-class">code</a>] 
                  </li>
                  <li>
                     <strong> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12146">Threaded ensembles of autoencoders for stream learning</a>   </strong><br>
                     <strong>Yue Dong</strong> and Nathalie Japkowicz <br>
                     <em> <strong>Computational Intelligence</strong>, 2018 </em> [<a href="#">code</a>] 
                  </li>
                  <br>
                  <h4><u>Before 2018</u></h4>
                  <li>
                     <strong> <a href="https://link.springer.com/chapter/10.1007/978-3-319-34111-8_37">Threaded Ensembles of Supervised and Unsupervised Neural Networks for Stream Learning</a>   </strong><br>
                     <strong>Yue Dong</strong> and Nathalie Japkowicz <br>
                     <em> <strong>Canadian Conference on Artificial Intelligence</strong>, 2016 </em> <strong><font color='red'>(Best Paper Award)</font></strong> [<a href="#">code</a>] 
                  </li>
               </ul>
            </div>
         </section>
         <!-- Five -->
         <section id="five">
            <div class="container">
               <h3> Services </h3>
               <ul>
                  <h4> Co-organizer </h4>
                  <ul>
                     - <strong> NeurIPS 2022 </strong> workshop on <a href="https://neurips2022-enlsp.github.io/">Efficient Natural Language and Speech Processing (ENLSP-II)</a> <br>
                     - <strong> EMNLP 2021 </strong> workshop on <a href="https://summarization-workshop.github.io/">New Frontiers in Summarization</a> <br>
                     - <strong> NeurIPS 2021 </strong> workshop on <a href="https://neurips2021-nlp.github.io/">Efficient Natural Language and Speech Processing</a>  <br>
                     - <strong>  NAACL 2022 </strong> tutorial on  <a href="https://text-editing.github.io/"> Text Generation with Text-Editing Models </a> <br>
                  </ul>
                  <h4> Area Chair </h4>
                  <ul>
                     - <strong> EMNLP 2022 </strong> Summarization <br>
                     - <strong> ACL 2021 Nov.</strong> Rolling Review 
                  </ul>
                  <h4> Reviewer </h4>
                  <ul>
                     <strong> - 2022:</strong> ARR <br>
                     <strong> - 2021:</strong> ACL <br>
                     <strong> - 2020:</strong> COLING, EMNLP, IJCAI, ACL<br>
                     <strong> - 2019:</strong> EMNLP, ACL, IJCAI 
                  </ul>
               </ul>
            </div>
         </section>
         <!-- Six -->
         <section id="six">
            <div class="container">
               <h3> Teachings </h3>
               <strong> [Winter 2023] </strong> CS 260 - Seminar in Natural Language Processing <br>
               <strong> [Spring 2023] </strong> <a href="https://www.coursicle.com/ucr/courses/CS/173/"> CS 173 - Introduction to Natural Language Processing</a> 
            </div>
         </section>
         <!-- Seven -->
         <section id="seven">
            <div class="container">
               <h3> Awards </h3>
               <ul>
                  - Alexander Graham Bell Canada Graduate Scholarship - Doctoral (CGS D) - Accepted, 2018-2019 <br>
                  - NSERC Postgraduate Scholarship - Doctoral (PGS D) - Accepted, 2017-2018 <br>
                  - FRQNT Doctoral Scholarship - Declined (rank first in all 2016 applicants in mathematics), 2016 <br>
                  - FRQNT Master’s Research Scholarship, 2016<br>
                  - NSERC Canada Graduate Scholarships - CGS Master’s, 2015<br>
                  - University of Ottawa Excellence Scholarship, 2015 - 2016<br>
                  - NSERC Undergraduate Student Research Awards (USRA), Summer 2014<br>
                  - Dean’s Merit Scholarships - Faculty of Science, University of Ottawa, 2014<br>
                  - University of Ottawa Women’s Summer Research Award, Summer 2013<br>
                  - University of Ottawa Work/Study Research Award, Summer 2012<br>
                  <strong><font color='red'><a href="http://www.sneac.com/info/1009/2054.htm"> - First prize in mathematics competition in Shaanxi province, China</a></font>, 2008</strong> 
               </ul>
            </div>
         </section>
         
         <!-- Eight -->
         <section id="seven">
            <div class="container">
               <h3> Talks </h3>
               <ul>
                   <li>Robust and Trustworthy NLP Through The Lens of Text Summarization [<a href="images/yue_job_talk_2022.pdf">slides</a>]</li>
                  <ul>
                     - Invited Talk at University of California - Riverside, March 2021 <br>
                     - Invited Talk at University of National University of Singapore, March 2021<br>
                     - Invited Talk at Google AI, March 2021<br>
                     - Invited Talk at University of Waterloo, February 2021<br>
                     - Invited Talk at University of Utah, February 2021<br>
                     - Invited Talk at Simon Fraser University, February 2021<br>
                     - Invited Talk at HEC Montreal & Mila, February 2021<br>
                     - Invited Talk at University of Michigan - Dearborn, February 2021<br>
                     - Invited Talk at Queen's University, January 2021<br>
                   </ul> 
               </ul>
            </div>
         </section>
         
         <!-- Footer -->
         <section id="footer">
            <div class="container">
               <ul class="copyright">
                  <li>&copy; Yue Dong. All rights reserved.</li>
                  <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
               </ul>
            </div>
         </section>
      </div>
      <!-- Scripts -->
      <script src="assets/js/jquery.min.js"></script>
      <script src="assets/js/jquery.scrollex.min.js"></script>
      <script src="assets/js/jquery.scrolly.min.js"></script>
      <script src="assets/js/browser.min.js"></script>
      <script src="assets/js/breakpoints.min.js"></script>
      <script src="assets/js/util.js"></script>
      <script src="assets/js/main.js"></script>
      <div class="container">
         <div align="center">
           <a href="https://clustrmaps.com/site/1bo27"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=95SlR4OePjK4kamqupzQ0eGQuhABu01nkcjYDegv_bg&cl=ffffff" style="display: none;" /></a>
         </div>
      </div>
      </td>
      </tr>
      </table>
      <script xml:space="preserve" language="JavaScript">
         hideallbibs();
      </script>
   </body>
</html>
